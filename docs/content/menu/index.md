---
headless: true
---

- [**Home**]({{< relref "/" >}})
- [**Attack Types**]({{< relref "/attacks" >}})
  - [Adversarial Examples]({{< relref "/attacks/adversarial" >}})
  - [Data Poisoning]({{< relref "/attacks/data-poisoning" >}})
  - [Model Inversion]({{< relref "/attacks/model-inversion" >}})
  - [Membership Inference]({{< relref "/attacks/membership-inference" >}})
  - [Query Manipulation]({{< relref "/attacks/query-manipulation" >}})
- [**Resources**](#)
  - [GitHub Repository](https://github.com/AI-Security-Research-Group/LLM-Attacks)
  - [License](https://github.com/AI-Security-Research-Group/LLM-Attacks/blob/main/LICENSE)
